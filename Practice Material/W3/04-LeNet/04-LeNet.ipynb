{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LeNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJejm-ZRMB0x"
      },
      "source": [
        "# LeNet-5\n",
        "In this homework you will use PyTorch to build and train a convolutional network. You are asked to implement the a modified LeNet-5 for MINIST digits classification. Different from the original LeNet-5, in this notebook we use max instead of average pooling, and use fully connected instead of gaussian final layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rPoZrLgMB0y"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from IPython import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YIzSTkMMB02"
      },
      "source": [
        "# grayscale and inline plotting\n",
        "%matplotlib inline\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI2cHk8zufts"
      },
      "source": [
        "## Visualization tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCkbK86VMB07"
      },
      "source": [
        "def plot_image(image):\n",
        "    nr, nc = image.shape\n",
        "    extent = [-0.5, nc - 0.5, nr - 0.5, -0.5]\n",
        "    plt.imshow(image, extent=extent, origin='upper', interpolation='nearest')\n",
        "\n",
        "def visualize(t, loss, errcl, x5, x4, x3, x0, w1):\n",
        "\n",
        "    loss_avg = np.divide(\n",
        "        np.cumsum(loss[: t + 1]),\n",
        "        range(1, t + 2)\n",
        "    )\n",
        "\n",
        "    errcl_avg = np.divide(\n",
        "        np.cumsum(errcl[: t + 1]),\n",
        "        range(1, t + 2)\n",
        "    )\n",
        "\n",
        "    n_last_batches = np.min([20, t])\n",
        "    k = np.ones(n_last_batches * 2 + 1) / (n_last_batches + 1)\n",
        "    k[:n_last_batches] = 0\n",
        "    \n",
        "    errcl_sm = np.convolve(np.pad(errcl, mode=\"edge\", pad_width=n_last_batches), k, mode=\"valid\")\n",
        "    errcl_sm = errcl_sm[: len(errcl_avg)]\n",
        "\n",
        "    loss_sm = np.convolve(np.pad(loss, mode=\"edge\", pad_width=n_last_batches), k, mode=\"valid\")\n",
        "    loss_sm = loss_sm[: len(loss)]\n",
        "\n",
        "    display.clear_output(wait=True)\n",
        "\n",
        "    plt.subplot(4, 3, 1)\n",
        "    plt.plot(loss, label=\"loss\")\n",
        "    plt.plot(loss_sm, label=\"smothed loss\")\n",
        "    plt.plot(loss_avg, label=\"avg loss\")\n",
        "    plt.legend()\n",
        "    plt.ylim(0, np.max(loss)*1.05)\n",
        "    plt.title(\"loss: avg - %.4f, smoothed - %.4f, current - %.4f\"  % (loss_avg[t], loss_sm[t], loss[t]))\n",
        "\n",
        "    plt.subplot(4, 3, 2)\n",
        "    plt.plot(errcl, label=\"cl err\")\n",
        "    plt.plot(errcl_sm, label=\"smothed cl err\")\n",
        "    plt.plot(errcl_avg, label=\"avg cl err\")\n",
        "    plt.legend()\n",
        "    plt.ylim(0, np.max(errcl)*1.05)\n",
        "    plt.title(\"cl error: avg - %.4f, smoothed - %.4f, current - %.4f\"  % (errcl_avg[t], errcl_sm[t], errcl[t]))\n",
        "    \n",
        "    plt.subplot(4, 3, 3)\n",
        "    plt.bar(range(len(x5)), x5)\n",
        "    plt.title(\"class confidences\")\n",
        "\n",
        "    plt.subplot(4,3,4)\n",
        "    plt.hist(x4)\n",
        "    plt.title(\"F6 activations\")\n",
        "\n",
        "    plt.subplot(4,3,5)\n",
        "    plt.hist(x3)\n",
        "    plt.title(\"C5 activations\")\n",
        "\n",
        "    plt.subplot(4,3,6)\n",
        "    plot_image(x0)\n",
        "    plt.title(\"input image\")\n",
        "\n",
        "    for i in range(w1.shape[0]):\n",
        "        plt.subplot(4,3,7+i)\n",
        "        plot_image(w1[i])\n",
        "        plt.title(\"C1 kernel channel \" + str(i))\n",
        "\n",
        "    plt.subplots_adjust(wspace=0.5)\n",
        "    plt.subplots_adjust(hspace=0.5)\n",
        "    plt.gcf().set_size_inches(18.5, 10.5)\n",
        "    display.display(plt.gcf())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWBhNjnKul-6"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc7hIpVjuZG3"
      },
      "source": [
        "# get data\n",
        "\n",
        "import urllib\n",
        "try:\n",
        "    # For python 2\n",
        "    class AppURLopener(urllib.FancyURLopener):\n",
        "        version = \"Mozilla/5.0\"\n",
        "\n",
        "    urllib._urlopener = AppURLopener()\n",
        "except AttributeError:\n",
        "    # For python 3\n",
        "    opener = urllib.request.build_opener()\n",
        "    opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "    urllib.request.install_opener(opener)\n",
        "\n",
        "mnist = torchvision.datasets.MNIST(root='data', train=True, download=True) # train data only\n",
        "trainimages = mnist.data\n",
        "trainlabels = mnist.targets\n",
        "\n",
        "# check training data shape\n",
        "print \"Training Data shape is: \", list(trainimages.size())\n",
        "print \"Training Target shape is: \", list(trainlabels.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfsxXO4RxgLC"
      },
      "source": [
        "## LeNet-5 Architecture\n",
        "\n",
        "![Original Architecture of LeNet-5](https://miro.medium.com/max/4308/1*1TI1aGBZ4dybR6__DI9dzA.png)\n",
        "\n",
        "The original architecture of LeNet-5. In this homework, we use max instead of average pooling for subsampling, and use fully connected instead of gaussian final layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNfECWDixOHI"
      },
      "source": [
        "## PyTorch Implementation\n",
        "\n",
        "Please complete the definition of layers and forward pass in the following starter code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzJHjxSVMB1H"
      },
      "source": [
        "class LeNet5(nn.Module):\n",
        "\n",
        "    # definition of each neural network layer\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.C1 = nn.Conv2d(1, 6, kernel_size=(5, 5))\n",
        "        self.S2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "\n",
        "        ####### Complete the defition of C3 and S4 ##########\n",
        "        # C3 is a convolutional layer with 16 5x5 kernels\n",
        "        # S4 is a max pooling layer with 2x2 kernel and stride 2\n",
        "\n",
        "        # self.C3 = ??\n",
        "        # self.S4 = ??\n",
        "        \n",
        "        #####################################################\n",
        "\n",
        "        self.C5 = nn.Conv2d(16, 120, kernel_size=(5, 5))\n",
        "        self.F6 = nn.Linear(120, 84)\n",
        "\n",
        "        # output layer\n",
        "        self.OL = nn.Linear(84, 10)\n",
        "        \n",
        "        # record C5 & F6 activation for visualization\n",
        "        self.record = {\"C5\":None, \"F6\":None}\n",
        "\n",
        "    # definition of the forward pass\n",
        "    def forward(self, x):\n",
        "        \n",
        "        # input x are (batch, 1, 32, 32) grayscale images\n",
        "        # the first convolutional layer C1 with 6 kernels size 5×5 and a stride of 1\n",
        "        # output image size changes from (batch, 1, 32, 32) to (batch, 6, 28, 28)\n",
        "        # then pass the feature maps to the tanh activation function\n",
        "        x = torch.tanh(self.C1(x))\n",
        "\n",
        "        # pass the feature maps to a 2x2 max pooling layer S2 \n",
        "        # the output image dimension decreases halved -> (batch, 6, 14, 14)\n",
        "        x = self.S2(x)\n",
        "        \n",
        "        ####### Complete the foward pass C3 > S4 > C5 ###################################\n",
        "        # C3 is the second convolutional layer with 16 kernels size 5×5 and a stride of 1\n",
        "        # after C3, the output image size changes from (batch, 6, 14, 14) to (batch, 16, 10, 10)\n",
        "        # S4 is the second 2x2 pooling layer with strid 2\n",
        "        # after S4, the output image size changes from (batch, 16, 10, 10) to (batch, 16, 5, 5)\n",
        "        # C5 is the third convolutional layer with 120 kernels size 5×5 and a stride of 1\n",
        "        # after C5, the output image size changes from (batch, 16, 5, 5) to (batch, 120, 1, 1)\n",
        "        # C3, C5 is followed by tanh activations\n",
        "\n",
        "        # x = ??\n",
        "\n",
        "        ##################################################################################\n",
        "\n",
        "        # convert (batch, 120, 1, 1) feature maps to 1d features of size (batch, 120)\n",
        "        x = x.view(x.size(0), -1) \n",
        "        \n",
        "        # record the activation of C5 as a numpy array\n",
        "        # .detach() declares a tensor does not need gradients\n",
        "        # .numpy() convert a torch tensoer without gradient to numpy array\n",
        "        # independent of the forward pass, we have to make a copy of x by method .clone()\n",
        "        self.record[\"C5\"] = x.clone().detach().numpy()\n",
        "\n",
        "        # pass the activation to the fully connected layer F6 followed by a tanh activation\n",
        "        # output size changes from (batch, 120) to (batch, 86)\n",
        "        x = torch.tanh(self.F6(x))\n",
        "\n",
        "        # record the activat of F6 as numpy array\n",
        "        self.record[\"F6\"] = x.clone().detach().numpy()\n",
        "\n",
        "        # pass the activation to the final fully connected layer OL followed by a tanh activation\n",
        "        # output size changes from (batch, 86) to (batch, 10)\n",
        "        x = torch.tanh(self.OL(x))\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtyxZUX5f6_D"
      },
      "source": [
        "## Training with PyTorch\n",
        "\n",
        "Please read the following code carefully. Run the code to show that the learning curve goes down. (This code is written for pedagogical purposes, not efficiency.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvEkHlUmMB1J"
      },
      "source": [
        "ntrain = trainimages.shape[0];  # number of training examples\n",
        "nepoch = 10;                    # number of epochs through training set\n",
        "disp_freq = 100                 # display frequency\n",
        "batchsize = 32                  # minibatch size\n",
        "\n",
        "errs = []\n",
        "losses = []\n",
        "\n",
        "lenet5 = LeNet5()\n",
        "\n",
        "# use SGD optimizer, set learning rate parameter as 0.1\n",
        "optimizer = optim.SGD(lenet5.parameters(), lr=0.1)\n",
        "\n",
        "t_start = time.time()\n",
        "for iepoch in range(nepoch):\n",
        "    for t in range(int(ntrain / batchsize)):\n",
        "        batchindices = np.random.choice(ntrain, batchsize, replace=False)\n",
        "        trainlabels_iter = trainlabels[batchindices]\n",
        "        \n",
        "        # label 1 for the correct digit and -1 for the incorrect digits\n",
        "        y = torch.ones(10, batchsize) * (-1)\n",
        "        y[trainlabels_iter, torch.arange(batchsize, dtype=torch.int64)] = 1\n",
        "\n",
        "        # normalize input images\n",
        "        imgs = torch.zeros([batchsize, 1, 32, 32])\n",
        "        imgs[:, 0, 2: -2, 2: -2] = trainimages[batchindices].float() / 255.\n",
        "\n",
        "        # before the forward pass, clean the gradient buffers of all parameters\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        out = lenet5(imgs)\n",
        "        \n",
        "        # MSE loss\n",
        "        loss = torch.mean(0.5*(y - out.t())**2)\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update parameters using SGD\n",
        "        optimizer.step()\n",
        "\n",
        "        # calculate error rate and loss for plot\n",
        "        pred = torch.argmax(out, dim=1)\n",
        "        err = torch.mean((pred != trainlabels_iter).float())\n",
        "        errs.append(err.detach().numpy())\n",
        "        losses.append(loss.detach().numpy())\n",
        "\n",
        "        \n",
        "        # plots\n",
        "        if (t + 1) % disp_freq == 0:\n",
        "            plt.gcf().clear()\n",
        "            visualize(len(errs) - 1, losses, errs, out[0,:].detach(), lenet5.record[\"F6\"][:, 0], \n",
        "                      lenet5.record[\"C5\"][:, 0], imgs[0, 0].detach(), lenet5.C1.weight.detach().squeeze())\n",
        "            print(str(time.time() - t_start) + \" seconds per \" + str(disp_freq) + \" iterations\")\n",
        "            t_start = time.time()\n",
        "            time.sleep(0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp9ObStgUgyx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDy-y9XqivNA"
      },
      "source": [
        "### Use ReLU activation and change C5 to F5\n",
        "Now let's implement a varant of LeNet-5, use `ReLU` activation function instead of `tanh` activation function for each layer. And change the convolutional layer C5 in the original net work to a fully connected layer F5. You will have to use softmax as the network output. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPlUN_KAivi7"
      },
      "source": [
        "class LeNet5_Relu(nn.Module):\n",
        "\n",
        "    # definition of each neural network layer\n",
        "    def __init__(self):\n",
        "        super(LeNet5_Relu, self).__init__()\n",
        "        self.C1 = nn.Conv2d(1, 6, kernel_size=(5, 5))\n",
        "        self.S2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        self.C3 = nn.Conv2d(6, 16, kernel_size=(5, 5))\n",
        "        self.S4 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
        "        \n",
        "        ####### Complete the defition of F5 #################\n",
        "        \n",
        "        \n",
        "\n",
        "        #####################################################\n",
        "\n",
        "        self.F6 = nn.Linear(120, 84)\n",
        "\n",
        "        # output layer\n",
        "        self.OL = nn.Linear(84, 10)\n",
        "        \n",
        "        # record C5 & C6 activation for visualization\n",
        "        self.record = {\"F5\":None, \"F6\":None}\n",
        "\n",
        "    # definition of the forward pass\n",
        "    def forward(self, x):\n",
        "        \n",
        "        ####### Complete the foward pass C1 >> F5 ##########\n",
        "        \n",
        "        \n",
        "\n",
        "        #####################################################\n",
        "\n",
        "        self.record[\"F5\"] = x.clone().detach().numpy()\n",
        "        x = torch.relu(self.F6(x))\n",
        "        self.record[\"F6\"] = x.clone().detach().numpy()\n",
        "        x = functional.softmax(self.OL(x), dim=1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}